# IBM-Project-21849-1659792778

## Project Title: Real-Time Communication System Powered by AI for Specially Abled

# HUMAN - AI INTERACTION

### Team ID: PNT2022TMID22298
-----------------------------------------------------------------------

Team Leader : Girishun Kumar R

Team Member : Kishore M

Team Member : Sri Nandhish Kumar

Team Member : Jaikrishnan

-----------------------------------------------------------------------
Industry Mentor(s) Name : Divya

Faculty Mentor(s) Name : Vinod S

----------------------------------------------------------------------
Degree : Bachelor of Engineering

Branch : Computer Science Engineering

College : Vel Tech Multi Tech Dr. Rangarajan Dr. Sakunthala Engineering College

-------------------------------------------------------------------------
### Objective:
 
 The project aim is to develop an artificial intelligence model that converts sign language into a speech that can be understood by normal people
 
 ------------------------------------------------------------------------
### Project Description:
   
   In our society, we have people with disabilities. The technology is developing day by day but no significant developments are undertaken for the betterment of these people. Communications between deaf-mute and a normal person has always been a challenging task. It is very difficult for mute people to convey their message to normal people. Since normal people are not trained on hand sign language. In emergency times conveying their message is very difficult. The human hand has remained a popular choice to convey information in situations where other forms like speech cannot be used. Voice Conversion System with Hand Gesture Recognition and translation will be very useful to have a proper conversation between a normal person and an impaired person in any language.
   
   The project aims to develop a system that converts the sign language into a human hearing voice in the desired language to convey a message to normal people, as well as convert speech into understandable sign language for the deaf and dumb. We are making use of a convolution neural network to create a model that is trained on different hand gestures. An app is built which uses this model. This app enables deaf and dumb people to convey their information using signs which get converted to human-understandable language and speech is given as output.

---------------------------------------------------------------------------
### Technical Architecture:
![download](https://user-images.githubusercontent.com/102667614/200394275-ec2ae5dc-40bb-47d8-bbdf-dcb4e209fafc.png)
---------------------------------------------------------------------------

### The result of our project is uploaded in below in link

https://drive.google.com/file/d/1390RV9-duu075ZPL_KoUVQKgoWBnFA6r/view?usp=drivesdk

### Feedback:
If you have any feedback, please reach out to us at girishunkumarnov21@gmail.com

----------------------------------------------------------------------
### Thank You
